{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Installing libraries","metadata":{}},{"cell_type":"code","source":"# Looking available GPU\n!nvidia-smi -L","metadata":{"execution":{"iopub.status.busy":"2022-01-26T07:08:13.845094Z","iopub.execute_input":"2022-01-26T07:08:13.845357Z","iopub.status.idle":"2022-01-26T07:08:14.534689Z","shell.execute_reply.started":"2022-01-26T07:08:13.845325Z","shell.execute_reply":"2022-01-26T07:08:14.533822Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Istalling efficientnet \n# Now models can be build with Keras or Tensorflow frameworks \n!pip install -q efficientnet","metadata":{"execution":{"iopub.status.busy":"2022-01-26T07:08:14.536599Z","iopub.execute_input":"2022-01-26T07:08:14.537104Z","iopub.status.idle":"2022-01-26T07:08:21.786069Z","shell.execute_reply.started":"2022-01-26T07:08:14.537063Z","shell.execute_reply":"2022-01-26T07:08:21.785186Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# Install custom image data generator for tensorflow.keras that supports albumentations\n!pip install git+https://github.com/mjkvaak/ImageDataAugmentor","metadata":{"execution":{"iopub.status.busy":"2022-01-26T07:08:21.788297Z","iopub.execute_input":"2022-01-26T07:08:21.788589Z","iopub.status.idle":"2022-01-26T07:08:31.322663Z","shell.execute_reply.started":"2022-01-26T07:08:21.788549Z","shell.execute_reply":"2022-01-26T07:08:31.321774Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# Install Python library for image augmentation with large set of image transformations\n!pip install -U albumentations==1.0.3","metadata":{"execution":{"iopub.status.busy":"2022-01-26T07:08:31.324973Z","iopub.execute_input":"2022-01-26T07:08:31.325197Z","iopub.status.idle":"2022-01-26T07:08:38.721296Z","shell.execute_reply.started":"2022-01-26T07:08:31.325167Z","shell.execute_reply":"2022-01-26T07:08:38.720469Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pickle\nimport zipfile\nimport csv\nimport sys\nimport os\nimport itertools\nfrom skimage import io\n\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing import image\n#from tensorflow.keras.preprocessing.image import ImageDataGenerator \n\nfrom ImageDataAugmentor.image_data_augmentor import *\nimport albumentations\n\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n# LearningRateScheduler\nfrom tensorflow.keras.callbacks import Callback\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.models import load_model\n#from tensorflow.keras.applications import EfficientNetB6 \nfrom tensorflow.keras.layers import *\nimport efficientnet.tfkeras as efn\n\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\n\nimport PIL\nfrom PIL import ImageOps, ImageFilter\n# increasing the default size of the charts\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 10, 5\n# graphs in svg look better\n%config InlineBackend.figure_format = 'svg' \n%matplotlib inline\n\nprint('Python          :', sys.version.split('\\n')[0])\nprint('Numpy           :', np.__version__)\nprint('Tensorflow      :', tf.__version__)\nprint('Keras           :', tf.keras.__version__)\nprint('Albumentations  :', albumentations.__version__)","metadata":{"execution":{"iopub.status.busy":"2022-01-26T07:08:38.723779Z","iopub.execute_input":"2022-01-26T07:08:38.724066Z","iopub.status.idle":"2022-01-26T07:08:38.758295Z","shell.execute_reply.started":"2022-01-26T07:08:38.724028Z","shell.execute_reply":"2022-01-26T07:08:38.757465Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# Checking that GPU is working\ntf.test.gpu_device_name()","metadata":{"execution":{"iopub.status.busy":"2022-01-26T07:08:38.759640Z","iopub.execute_input":"2022-01-26T07:08:38.760116Z","iopub.status.idle":"2022-01-26T07:08:38.774894Z","shell.execute_reply.started":"2022-01-26T07:08:38.760077Z","shell.execute_reply":"2022-01-26T07:08:38.774139Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"!pip freeze > requirements.txt","metadata":{"execution":{"iopub.status.busy":"2022-01-26T07:08:38.776237Z","iopub.execute_input":"2022-01-26T07:08:38.776511Z","iopub.status.idle":"2022-01-26T07:08:41.193805Z","shell.execute_reply.started":"2022-01-26T07:08:38.776476Z","shell.execute_reply":"2022-01-26T07:08:41.192817Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"## Setup","metadata":{}},{"cell_type":"code","source":"# In setup, we make the basic settings: it's more convenient to sort them out in the future.\n\nEPOCHS               = 5  # number of epochs for learning\nBATCH_SIZE           = 64 # reduce the batch if the network is large, otherwise it will not fit into the memory on the GPU\nLR                   = 1e-3\nVAL_SPLIT            = 0.2 # the proportion of data allocated to the test = 20%\n\nCLASS_NUM            = 10  # the number of classes in task\nIMG_SIZE             = 224 # size of pictures that we send in model\nIMG_CHANNELS         = 3   # RGB has 3 channel\ninput_shape          = (IMG_SIZE, IMG_SIZE, IMG_CHANNELS)\n\nDATA_PATH = '../input/sf-dl-car-classification/' # data directory\nPATH = \"../working/car/\" # working directory\nPATH_BEST_MODEL = \"../working/\" # directory for save and load model when model is training","metadata":{"execution":{"iopub.status.busy":"2022-01-26T07:08:41.195495Z","iopub.execute_input":"2022-01-26T07:08:41.195772Z","iopub.status.idle":"2022-01-26T07:08:41.203661Z","shell.execute_reply.started":"2022-01-26T07:08:41.195735Z","shell.execute_reply":"2022-01-26T07:08:41.202376Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# Setting a specific random seed value for reproducibility\ntry:\n    os.makedirs(PATH,exist_ok=True)\nexcept FileExistsError:\n    print(\"File exists: '../working/car/'\")\n    \ntry:\n    os.makedirs(PATH_BEST_MODEL,exist_ok=True)\nexcept FileExistsError:\n    print(\"File exists: '../working/calc_models/'\")\n\nRANDOM_SEED = 42\nnp.random.seed(RANDOM_SEED)  \nPYTHONHASHSEED = 0","metadata":{"execution":{"iopub.status.busy":"2022-01-26T07:08:41.205170Z","iopub.execute_input":"2022-01-26T07:08:41.205604Z","iopub.status.idle":"2022-01-26T07:08:41.215207Z","shell.execute_reply.started":"2022-01-26T07:08:41.205562Z","shell.execute_reply":"2022-01-26T07:08:41.214451Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"## EDA","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv(DATA_PATH+\"train.csv\")\nsample_submission = pd.read_csv(DATA_PATH+\"sample-submission.csv\")\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-26T07:08:41.218563Z","iopub.execute_input":"2022-01-26T07:08:41.218957Z","iopub.status.idle":"2022-01-26T07:08:41.246638Z","shell.execute_reply.started":"2022-01-26T07:08:41.218921Z","shell.execute_reply":"2022-01-26T07:08:41.245923Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"train_df.info()","metadata":{"execution":{"iopub.status.busy":"2022-01-26T07:08:41.247906Z","iopub.execute_input":"2022-01-26T07:08:41.248455Z","iopub.status.idle":"2022-01-26T07:08:41.262596Z","shell.execute_reply.started":"2022-01-26T07:08:41.248418Z","shell.execute_reply":"2022-01-26T07:08:41.261867Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"train_df.Category.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-01-26T07:08:41.264445Z","iopub.execute_input":"2022-01-26T07:08:41.264685Z","iopub.status.idle":"2022-01-26T07:08:41.274311Z","shell.execute_reply.started":"2022-01-26T07:08:41.264649Z","shell.execute_reply":"2022-01-26T07:08:41.273285Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"### Preliminary conclusion:\nIn the task block when building the Baseline, it is specified: \"The distribution of classes is fairly uniform — that's good.\" This does not seem to be true, since there is a difference of more than 30% in the amount of data for individual classes in the training sample. You can upload data from other sources for a more even distribution of classes.","metadata":{}},{"cell_type":"code","source":"print('Unzip pictures')\n# Will unzip the files so that you can see them..\nfor data_zip in ['train.zip', 'test.zip']:\n    with zipfile.ZipFile(DATA_PATH+data_zip,\"r\") as z:\n        z.extractall(PATH)\n        \nprint(os.listdir(PATH))","metadata":{"execution":{"iopub.status.busy":"2022-01-26T07:08:41.275691Z","iopub.execute_input":"2022-01-26T07:08:41.276159Z","iopub.status.idle":"2022-01-26T07:08:58.367851Z","shell.execute_reply.started":"2022-01-26T07:08:41.276117Z","shell.execute_reply":"2022-01-26T07:08:58.367084Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"print('Picture examples (random sample)')\nplt.figure(figsize=(12,8))\n\nrandom_image = train_df.sample(n=9)\nrandom_image_paths = random_image['Id'].values\nrandom_image_cat = random_image['Category'].values\n\nfor index, path in enumerate(random_image_paths):\n    im = PIL.Image.open(PATH+f'train/{random_image_cat[index]}/{path}')\n    plt.subplot(3,3, index+1)\n    plt.imshow(im)\n    plt.title('Class: '+str(random_image_cat[index]))\n    plt.axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-26T07:08:58.369151Z","iopub.execute_input":"2022-01-26T07:08:58.369416Z","iopub.status.idle":"2022-01-26T07:08:59.157850Z","shell.execute_reply.started":"2022-01-26T07:08:58.369368Z","shell.execute_reply":"2022-01-26T07:08:59.151187Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# An example of a picture with dimensions to understand how best to process and compress images\nimage = PIL.Image.open(PATH + '/train/0/100380.jpg')\nimgplot = plt.imshow(image)\nplt.show()\nimage.size","metadata":{"execution":{"iopub.status.busy":"2022-01-26T07:08:59.159226Z","iopub.execute_input":"2022-01-26T07:08:59.159698Z","iopub.status.idle":"2022-01-26T07:08:59.428614Z","shell.execute_reply.started":"2022-01-26T07:08:59.159659Z","shell.execute_reply":"2022-01-26T07:08:59.427956Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"## Data preparation","metadata":{}},{"cell_type":"markdown","source":"### Augmentation Data","metadata":{}},{"cell_type":"code","source":"# Creating a function for image data generator with augmentations transformations \n# I choose transformations that more approximate to images in task \n# that why I exclude transformations and distortions of forms of cars \n# but we can try use it in training model\ndef augment_data():\n    AUGMENTATIONS = albumentations.Compose([\n        albumentations.CLAHE(p=0.25, clip_limit=(1, 10), tile_grid_size=(10, 10)),\n        albumentations.ChannelShuffle(p=0.25),\n        #albumentations.Downscale(p=0.25, scale_min=0.75, scale_max=0.99, interpolation=1),\n        #albumentations.ElasticTransform(p=0.25, alpha=1.0, sigma=10, alpha_affine=10, \n        #                                interpolation=1, border_mode=1, value=(0, 0, 0), \n        #                                mask_value=None, approximate=False),\n        albumentations.Equalize(p=0.25, mode='cv', by_channels=True),\n        albumentations.GaussNoise(p=0.25, var_limit=(10.0, 500.0), mean=-10),\n        #albumentations.GridDistortion(p=0.25, num_steps=15, distort_limit=(-0.3, 0.3), \n        #                              interpolation=3, border_mode=1, value=(0, 0, 0), \n        #                              mask_value=None),\n        albumentations.HorizontalFlip(p=0.5),\n        albumentations.HueSaturationValue(p=0.5, hue_shift_limit=(-20, 20), \n                                          sat_shift_limit=(-20, 20), val_shift_limit=(-20, 20)),\n        #albumentations.ISONoise(p=0.5, intensity=(0.1, 0.4), color_shift=(0.01, 0.3)),\n        albumentations.MotionBlur(p=0.25, blur_limit=(3, 7)),\n        #albumentations.OpticalDistortion(p=0.25, distort_limit=(-0.3, 0.3), \n        #                                 shift_limit=(-0.2, 0.2), interpolation=2, \n        #                                 border_mode=1, value=(0, 0, 0), mask_value=None),\n        albumentations.RGBShift(p=0.5),\n        albumentations.OneOf([\n            albumentations.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2),\n            albumentations.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1),\n            ],p=0.5),\n        albumentations.RandomGamma(p=0.25, gamma_limit=(100, 130), eps=1e-07),\n        #albumentations.RandomSnow(p=0.25, snow_point_lower=0.25, snow_point_upper=0.75, \n        #                          brightness_coeff=1.2),\n        albumentations.Rotate(p=0.5, limit=(-5, 5), interpolation=2, border_mode=2)\n    ])\n\n    train_datagen = ImageDataAugmentor(\n        rescale=1./255,\n        validation_split=VAL_SPLIT,\n        seed=RANDOM_SEED,\n        augment=AUGMENTATIONS,\n        preprocess_input=None)\n\n    test_datagen = ImageDataAugmentor(rescale=1./255,\n                                      seed=RANDOM_SEED,\n                                      )\n    return train_datagen, test_datagen\n\ntrain_datagen, test_datagen = augment_data()","metadata":{"execution":{"iopub.status.busy":"2022-01-26T07:09:38.022843Z","iopub.execute_input":"2022-01-26T07:09:38.023386Z","iopub.status.idle":"2022-01-26T07:09:38.035742Z","shell.execute_reply.started":"2022-01-26T07:09:38.023340Z","shell.execute_reply":"2022-01-26T07:09:38.034888Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"### Generation Data","metadata":{}},{"cell_type":"code","source":"# Create data generators\ndef generators(IMG_SIZE=IMG_SIZE, BATCH_SIZE_FOR_GEN=BATCH_SIZE):\n    train_generator = train_datagen.flow_from_directory(\n        PATH+'train/',      # the directory where the folders with pictures are located\n        target_size=(IMG_SIZE, IMG_SIZE),\n        batch_size=BATCH_SIZE_FOR_GEN,\n        class_mode='categorical',\n        shuffle=True, \n        subset='training') # set as training data\n\n    test_generator = train_datagen.flow_from_directory(\n        PATH+'train/',\n        target_size=(IMG_SIZE, IMG_SIZE),\n        batch_size=BATCH_SIZE_FOR_GEN,\n        class_mode='categorical',\n        shuffle=True, \n        subset='validation') # set as validation data\n\n    test_sub_generator = test_datagen.flow_from_dataframe( \n        dataframe=sample_submission,\n        directory=PATH+'test_upload/',\n        x_col=\"Id\",\n        y_col=None,\n        shuffle=False,\n        class_mode=None,\n        target_size=(IMG_SIZE, IMG_SIZE),\n        batch_size=BATCH_SIZE_FOR_GEN,)\n    return train_generator, test_generator, test_sub_generator\n\ntrain_generator, test_generator, test_sub_generator = generators()","metadata":{"execution":{"iopub.status.busy":"2022-01-26T07:09:42.010223Z","iopub.execute_input":"2022-01-26T07:09:42.010496Z","iopub.status.idle":"2022-01-26T07:09:43.138113Z","shell.execute_reply.started":"2022-01-26T07:09:42.010465Z","shell.execute_reply":"2022-01-26T07:09:43.137232Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"# Some examples of pictures in train_generator\ndef imshow(image_RGB):\n    io.imshow(image_RGB)\n    io.show()\n\nx,y = train_generator.next()\nprint('Some examples of pictures from train_generator')\nplt.figure(figsize=(12,8))\n\nfor i in range(0,6):\n    image = x[i]\n    plt.subplot(3,3, i+1)\n    plt.imshow(image)\n    #plt.title('Class: '+str(y[i]))\n    #plt.axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-26T07:09:45.478533Z","iopub.execute_input":"2022-01-26T07:09:45.479015Z","iopub.status.idle":"2022-01-26T07:09:47.088875Z","shell.execute_reply.started":"2022-01-26T07:09:45.478982Z","shell.execute_reply":"2022-01-26T07:09:47.088264Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"x,y = test_generator.next()\nprint('Some examples of pictures from test_generator')\nplt.figure(figsize=(12,8))\n\nfor i in range(0,6):\n    image = x[i]\n    plt.subplot(3,3, i+1)\n    plt.imshow(image)\n    #plt.title('Class: '+str(y[i]))\n    #plt.axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-26T07:09:50.302871Z","iopub.execute_input":"2022-01-26T07:09:50.303220Z","iopub.status.idle":"2022-01-26T07:09:51.884141Z","shell.execute_reply.started":"2022-01-26T07:09:50.303171Z","shell.execute_reply":"2022-01-26T07:09:51.883464Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"## Functions in calculations","metadata":{}},{"cell_type":"code","source":"# Callbacks that used for training model\ndef callbacks(lr):\n    checkpoint = ModelCheckpoint(PATH_BEST_MODEL+'best_model.hdf5', monitor='val_accuracy', \n                                 verbose=1, mode='max', save_best_only=True)\n    earlystop = EarlyStopping(monitor='val_accuracy', patience=6, restore_best_weights=True)\n    reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.2, patience=3, verbose=1,\n                                  min_lr=lr/100)\n    return [checkpoint, earlystop, reduce_lr]\n\n# patience=3 on ReduceLROnPlateau in Steps: 1,2,3,4,5_1,5_2, \n# patience=2 on ReduceLROnPlateau in Steps: 5_3,5_4, ","metadata":{"execution":{"iopub.status.busy":"2022-01-26T07:09:56.088869Z","iopub.execute_input":"2022-01-26T07:09:56.089598Z","iopub.status.idle":"2022-01-26T07:09:56.096330Z","shell.execute_reply.started":"2022-01-26T07:09:56.089551Z","shell.execute_reply":"2022-01-26T07:09:56.095473Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"# Function to save pictures of training model history\ndef plot_save_fig(history, num_step,\n                  PATH_BEST_MODEL=PATH_BEST_MODEL):\n    \n    \"\"\"\n    history - create from model.fit\n    num_step - integer which is a sequential number step in fine-tunning model\n    \n    \"\"\"\n    \n    plt.figure(figsize=(10,5))\n    #plt.style.use('dark_background')\n    acc = history.history['accuracy']\n    val_acc = history.history['val_accuracy']\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n\n    epochs = range(len(acc))\n\n    plt.plot(epochs, acc, 'b', label='Training acc')\n    plt.plot(epochs, val_acc, 'r', label='Validation acc')\n    plt.title('Training and validation accuracy')\n    plt.legend()\n    plt.savefig(PATH_BEST_MODEL + 'Train_Vall_acc_st_' + str(num_step) + '.png')\n\n    #plt.figure()\n    plt.figure(figsize=(10,5))\n    #plt.style.use('dark_background')\n    plt.plot(epochs, loss, 'b', label='Training loss')\n    plt.plot(epochs, val_loss, 'r', label='Validation loss')\n    plt.title('Training and validation loss')\n    plt.legend()\n    plt.savefig(PATH_BEST_MODEL + 'Train_Vall_loss_st_' + str(num_step) + '.png')","metadata":{"execution":{"iopub.status.busy":"2022-01-26T07:09:59.176494Z","iopub.execute_input":"2022-01-26T07:09:59.177032Z","iopub.status.idle":"2022-01-26T07:09:59.186609Z","shell.execute_reply.started":"2022-01-26T07:09:59.176995Z","shell.execute_reply":"2022-01-26T07:09:59.185846Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"# Function to print pictures of training model history in notebook without locally saving\ndef plot_history(history):\n    \n    \"\"\"\n    history - create from model.fit\n        \n    \"\"\"\n    \n    plt.figure(figsize=(10,5))\n    #plt.style.use('dark_background')\n    acc = history.history['accuracy']\n    val_acc = history.history['val_accuracy']\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n\n    epochs = range(len(acc))\n\n    plt.plot(epochs, acc, 'b', label='Training acc')\n    plt.plot(epochs, val_acc, 'r', label='Validation acc')\n    plt.title('Training and validation accuracy')\n    plt.legend()\n\n    #plt.figure()\n    plt.figure(figsize=(10,5))\n    #plt.style.use('dark_background')\n    plt.plot(epochs, loss, 'b', label='Training loss')\n    plt.plot(epochs, val_loss, 'r', label='Validation loss')\n    plt.title('Training and validation loss')\n    plt.legend()\n\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-26T07:10:02.428045Z","iopub.execute_input":"2022-01-26T07:10:02.428311Z","iopub.status.idle":"2022-01-26T07:10:02.436834Z","shell.execute_reply.started":"2022-01-26T07:10:02.428280Z","shell.execute_reply":"2022-01-26T07:10:02.435878Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"# Function to create model to load earlier saved best weights from training model\n\ndef build_best_model(f_tune_coef, LR, \n                     train_all_base_layers=False,\n                     PATH=PATH_BEST_MODEL,\n                     WEIGHTS_NAME='best_model.hdf5',\n                     input_shape=input_shape, \n                     BATCH_SIZE=BATCH_SIZE, \n                     trainable=True):\n    \n    \"\"\"\n    f_tune_coef - coefficient that define integer number \"fine_tune_at\" \n                  layers before fine_tune_at - will be freeze\n                  layers onwards - will be Fine-tuned (works with train_all_base_layers==False),\n    train_all_base_layers - if True all layers will be trainable (f_tune_coef - any from 1 to 588),\n    LR - learning rate,\n    PATH - directory with files of previous saved weights of model to be loaded\n    WEIGHTS_NAME - name of file of previous saved weights of model to be loaded\n    input_shape, BATCH_SIZE - size of pictures & batch size may be changed in steps of training model\n    \n    \"\"\"\n    \n  \n    base_model = efn.EfficientNetB6(weights='imagenet', include_top=False, input_shape=input_shape)\n    base_model.trainable = trainable\n    \n    # Сhoose layers which weights will train and freeze  \n    if train_all_base_layers==False:\n        # Fine-tune from this layer onwards\n        fine_tune_at = int(len(base_model.layers)//f_tune_coef)\n\n        # Freeze all the layers before the `fine_tune_at` layer\n        for layer in base_model.layers[:fine_tune_at]:\n            layer.trainable =  False\n\n    # Creation new head:\n    x = base_model.output\n    x = GlobalAveragePooling2D()(x)\n    x = Dense(256, activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.25)(x)\n    \n    #  logistic layer -- 10 classes\n    predictions = Dense(CLASS_NUM, activation='softmax')(x)\n\n    #  this is the model we will train\n    model = Model(inputs=base_model.input, outputs=predictions)\n\n    print(\"Number of trainable_variables in model: \", \n          len(model.trainable_variables))\n\n    model.compile(loss=\"categorical_crossentropy\", \n                  optimizer=optimizers.Adam(learning_rate=LR), \n                  metrics=[\"accuracy\"])\n\n    model.load_weights(PATH + WEIGHTS_NAME)\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-01-26T07:10:09.555548Z","iopub.execute_input":"2022-01-26T07:10:09.556122Z","iopub.status.idle":"2022-01-26T07:10:09.565790Z","shell.execute_reply.started":"2022-01-26T07:10:09.556082Z","shell.execute_reply":"2022-01-26T07:10:09.564919Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":"## Step 1","metadata":{}},{"cell_type":"code","source":"input_shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_model = efn.EfficientNetB6(weights='imagenet', include_top=False, input_shape=input_shape)\n#print(base_model.summary() # to see summary information about base_model\n\n# first: train only the top layers (which were randomly initialized)\nbase_model.trainable = False\n\n# Creation new head:\nx = base_model.output\nx = GlobalAveragePooling2D()(x)\nx = Dense(256, activation='relu')(x)\nx = BatchNormalization()(x)\nx = Dropout(0.5)(x)\n\n#  logistic layer -- 10 classes\npredictions = Dense(CLASS_NUM, activation='softmax')(x)\n\n#  this is the model we will train\nmodel = Model(inputs=base_model.input, outputs=predictions)\n\n# numbers of layers and training variables\nprint(len(model.layers))\nprint(len(model.trainable_variables))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training","metadata":{}},{"cell_type":"code","source":"LR=0.0001\nmodel.compile(loss=\"categorical_crossentropy\", \n              optimizer=optimizers.Adam(learning_rate=LR), \n              metrics=[\"accuracy\"])\n\nscores = model.evaluate(test_generator, verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))\n\ncallbacks_list = callbacks(lr=LR)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training\nhistory = model.fit(\n        train_generator,\n        steps_per_epoch = train_generator.samples//train_generator.batch_size, #len(train_generator), #\n        validation_data = test_generator,\n        validation_steps = test_generator.samples//test_generator.batch_size, #len(test_generator), #\n        epochs = EPOCHS,\n        callbacks = callbacks_list\n)\n\nplot_history(history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save model & load best iteration after fitting (best_model):\nmodel.save(PATH_BEST_MODEL + 'model_step1.hdf5')\n\n# to save best model weights in file with individual name\nmodel.load_weights(PATH_BEST_MODEL + 'best_model.hdf5') \nmodel.save_weights(PATH_BEST_MODEL + 'best_model_st_1.hdf5')\n\nscores = model.evaluate(test_generator, verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 2","metadata":{}},{"cell_type":"code","source":"LR=0.00005\nBATCH_SIZE=32\n\n# if model continues training by other session\n# download file with weights 'best_model_st_1.hdf5' to PATH='../input/weights-aft-st-1/'\nmodel = build_best_model(f_tune_coef=2, LR=LR,\n                         #PATH='../input/weights-aft-st-1/',\n                         #WEIGHTS_NAME='best_model_st_1.hdf5'\n                        )\n\ntrain_datagen, test_datagen = augment_data()\ntrain_generator, test_generator, sub_test_generator = generators(BATCH_SIZE_FOR_GEN=BATCH_SIZE)\ncallbacks_list = callbacks(lr=LR)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training\nhistory = model.fit(\n        train_generator,\n        steps_per_epoch = train_generator.samples//train_generator.batch_size,\n        validation_data = test_generator, \n        validation_steps = test_generator.samples//test_generator.batch_size,\n        epochs = 10,\n        callbacks = callbacks_list\n)\n\nplot_history(history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save(PATH_BEST_MODEL + 'model_step2.hdf5')\n\n# to save best model weights in file with individual name\nmodel.load_weights(PATH_BEST_MODEL + 'best_model.hdf5') \nmodel.save_weights(PATH_BEST_MODEL + 'best_model_st_2.hdf5')\n\nscores = model.evaluate(test_generator, verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 3","metadata":{}},{"cell_type":"code","source":"LR=0.00005\nBATCH_SIZE=32\n\n# if model continues training by other session\n# download file with weights 'best_model_st_2.hdf5' to PATH='../input/weights-aft-st-2/'\nmodel = build_best_model(f_tune_coef=4, LR=LR,\n                         #PATH='../input/weights-aft-st-2/',\n                         #WEIGHTS_NAME='best_model_st_2.hdf5'\n                        )\n\ntrain_datagen, test_datagen = augment_data()\ntrain_generator, test_generator, sub_test_generator = generators(BATCH_SIZE_FOR_GEN=BATCH_SIZE)\ncallbacks_list = callbacks(lr=LR)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training\nhistory = model.fit(\n        train_generator,\n        steps_per_epoch = train_generator.samples//train_generator.batch_size,\n        validation_data = test_generator, \n        validation_steps = test_generator.samples//test_generator.batch_size,\n        epochs = 10,\n        callbacks = callbacks_list\n)\n\nplot_history(history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save(PATH_BEST_MODEL + 'model_step3.hdf5')\n\n# to save best model weights in file with individual name\nmodel.load_weights(PATH_BEST_MODEL + 'best_model.hdf5') \nmodel.save_weights(PATH_BEST_MODEL + 'best_model_st_3.hdf5')\n\nscores = model.evaluate(test_generator, verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 4","metadata":{}},{"cell_type":"code","source":"LR=0.00001\nBATCH_SIZE=16\n\n# if model continues training by other session\n# download file with weights 'best_model_st_3.hdf5' to PATH='../input/weights-aft-st-3/'\nmodel = build_best_model(f_tune_coef=588, LR=LR,\n                         train_all_base_layers=True,\n                         #PATH='../input/weights-aft-st_3/',\n                         #WEIGHTS_NAME='best_model_st_3.hdf5'\n                        )\n\ntrain_datagen, test_datagen = augment_data()\ntrain_generator, test_generator, sub_test_generator = generators(BATCH_SIZE_FOR_GEN=BATCH_SIZE)\ncallbacks_list = callbacks(lr=LR)\n\n# Check the trainable status of the individual layers\n#for layer in model.layers:\n#    print(layer, layer.trainable) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training\nhistory = model.fit(\n        train_generator,\n        steps_per_epoch = train_generator.samples//train_generator.batch_size,\n        validation_data = test_generator, \n        validation_steps = test_generator.samples//test_generator.batch_size,\n        epochs = 10,\n        callbacks = callbacks_list\n)\n\nplot_history(history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save(PATH_BEST_MODEL + 'model_step4.hdf5')\n\n# to save best model weights in file with individual name\nmodel.load_weights(PATH_BEST_MODEL + 'best_model.hdf5')\nmodel.save_weights(PATH_BEST_MODEL + 'best_model_st_4.hdf5')\n\nscores = model.evaluate(test_generator, verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 5_1 + Step 5_2","metadata":{}},{"cell_type":"code","source":"EPOCHS               = 10\nBATCH_SIZE           = 4 \nLR                   = 1e-5\nVAL_SPLIT            = 0.2\n\nCLASS_NUM            = 10\nIMG_SIZE             = 448\nIMG_CHANNELS         = 3\ninput_shape          = (IMG_SIZE, IMG_SIZE, IMG_CHANNELS)","metadata":{"execution":{"iopub.status.busy":"2022-01-17T18:11:20.56397Z","iopub.execute_input":"2022-01-17T18:11:20.564541Z","iopub.status.idle":"2022-01-17T18:11:20.57099Z","shell.execute_reply.started":"2022-01-17T18:11:20.564512Z","shell.execute_reply":"2022-01-17T18:11:20.570202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# if model continues training by other session\n# download file with weights 'best_model_st_4.hdf5' to PATH='../input/weights-aft-st-4/'\nmodel = build_best_model(f_tune_coef=588, LR=LR,\n                         train_all_base_layers=True, \n                         #PATH='../input/weights-aft-st-4/',\n                         #WEIGHTS_NAME='best_model_st_4.hdf5'\n                        )","metadata":{"execution":{"iopub.status.busy":"2022-01-17T18:11:28.721871Z","iopub.execute_input":"2022-01-17T18:11:28.722608Z","iopub.status.idle":"2022-01-17T18:11:44.217415Z","shell.execute_reply.started":"2022-01-17T18:11:28.722568Z","shell.execute_reply":"2022-01-17T18:11:44.216655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creation new data generators due to IMG_SIZE increase and BATCH_SIZE changes\n\nAUGMENTATIONS = albumentations.Compose([\n    albumentations.CLAHE(p=0.25, clip_limit=(1, 10), tile_grid_size=(10, 10)),\n    albumentations.ChannelShuffle(p=0.25),\n    albumentations.Equalize(p=0.25, mode='cv', by_channels=True),\n    albumentations.HorizontalFlip(p=0.5),\n    albumentations.MotionBlur(p=0.25, blur_limit=(3, 7)),\n    albumentations.RGBShift(p=0.5),\n    albumentations.OneOf([\n        albumentations.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2),\n        albumentations.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1),\n    ],p=0.5),\n    albumentations.Rotate(p=0.5, limit=(-5, 5), interpolation=2, border_mode=2)\n])\n\ntrain_datagen = ImageDataAugmentor(\n    rescale=1./255,\n    validation_split=VAL_SPLIT,\n    seed=RANDOM_SEED,\n    augment=AUGMENTATIONS,\n    preprocess_input=None)\n\ntrain_generator = train_datagen.flow_from_directory(\n    PATH+'train/',     # the directory where the folders with pictures are located\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True, \n    subset='training') # set as training data\n\ntest_generator = train_datagen.flow_from_directory(\n    PATH+'train/',\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True, \n    subset='validation') # set as validation data\n\ncallbacks_list = callbacks(lr=LR)","metadata":{"execution":{"iopub.status.busy":"2022-01-17T18:11:44.21923Z","iopub.execute_input":"2022-01-17T18:11:44.219788Z","iopub.status.idle":"2022-01-17T18:11:45.371722Z","shell.execute_reply.started":"2022-01-17T18:11:44.21975Z","shell.execute_reply":"2022-01-17T18:11:45.370946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training\nhistory = model.fit(\n        train_generator,\n        steps_per_epoch = train_generator.samples//train_generator.batch_size, \n        validation_data = test_generator,\n        validation_steps = test_generator.samples//test_generator.batch_size, \n        epochs = 8,\n        callbacks = callbacks_list\n)\n\nplot_history(history)","metadata":{"execution":{"iopub.status.busy":"2022-01-17T18:11:51.896063Z","iopub.execute_input":"2022-01-17T18:11:51.896456Z","iopub.status.idle":"2022-01-17T20:33:03.500727Z","shell.execute_reply.started":"2022-01-17T18:11:51.896424Z","shell.execute_reply":"2022-01-17T20:33:03.50005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save(PATH_BEST_MODEL + 'model_step5_1.hdf5')\n\n# to save best model weights in file with individual name\nmodel.load_weights(PATH_BEST_MODEL + 'best_model.hdf5')\nmodel.save_weights(PATH_BEST_MODEL + 'best_model_st_5_1.hdf5')\n\nscores = model.evaluate(test_generator, verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","metadata":{"execution":{"iopub.status.busy":"2022-01-17T20:33:03.504654Z","iopub.execute_input":"2022-01-17T20:33:03.505124Z","iopub.status.idle":"2022-01-17T20:34:26.311897Z","shell.execute_reply.started":"2022-01-17T20:33:03.505088Z","shell.execute_reply":"2022-01-17T20:34:26.311041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 'best_model_st_5_2.hdf5' - continues to fit the model (+6 epoch) with the same params after 'best_model_st_5_1.hdf5' (8 epoch)","metadata":{}},{"cell_type":"code","source":"# Training\nhistory = model.fit(\n        train_generator,\n        steps_per_epoch = train_generator.samples//train_generator.batch_size, \n        validation_data = test_generator,\n        validation_steps = test_generator.samples//test_generator.batch_size, \n        epochs = 6,\n        callbacks = callbacks_list\n)\n\nplot_history(history)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save(PATH_BEST_MODEL + 'model_step5_2.hdf5')\n\n# to save best model weights in file with individual name\nmodel.load_weights(PATH_BEST_MODEL + 'best_model.hdf5')\nmodel.save_weights(PATH_BEST_MODEL + 'best_model_st_5_2.hdf5')\n\nscores = model.evaluate(test_generator, verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 5_3","metadata":{}},{"cell_type":"code","source":"EPOCHS               = 8\nBATCH_SIZE           = 4 \nLR                   = 1e-6\nVAL_SPLIT            = 0.2\n\nCLASS_NUM            = 10\nIMG_SIZE             = 448\nIMG_CHANNELS         = 3\ninput_shape          = (IMG_SIZE, IMG_SIZE, IMG_CHANNELS)","metadata":{"execution":{"iopub.status.busy":"2022-01-26T07:10:23.179915Z","iopub.execute_input":"2022-01-26T07:10:23.180280Z","iopub.status.idle":"2022-01-26T07:10:23.187906Z","shell.execute_reply.started":"2022-01-26T07:10:23.180237Z","shell.execute_reply":"2022-01-26T07:10:23.186904Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"# if model continues training by other session\n# download file with weights 'best_model_st_5_2.hdf5' to PATH='../input/weights-aft-st-5_2/'\nmodel = build_best_model(f_tune_coef=588, LR=LR,\n                         train_all_base_layers=True,\n                         #PATH='../input/weights-aft-st-5-2/',\n                         #WEIGHTS_NAME='best_model_st_5_2.hdf5'\n                        )","metadata":{"execution":{"iopub.status.busy":"2022-01-23T09:06:10.779039Z","iopub.execute_input":"2022-01-23T09:06:10.779661Z","iopub.status.idle":"2022-01-23T09:06:30.069953Z","shell.execute_reply.started":"2022-01-23T09:06:10.779622Z","shell.execute_reply":"2022-01-23T09:06:30.069227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"AUGMENTATIONS = albumentations.Compose([\n    albumentations.CLAHE(p=0.25, clip_limit=(1, 10), tile_grid_size=(10, 10)),\n    albumentations.ChannelShuffle(p=0.25),\n    albumentations.Equalize(p=0.25, mode='cv', by_channels=True),\n    albumentations.HorizontalFlip(p=0.5),\n    albumentations.MotionBlur(p=0.25, blur_limit=(3, 7)),\n    albumentations.RGBShift(p=0.5),\n    albumentations.OneOf([\n        albumentations.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2),\n        albumentations.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1),\n    ],p=0.5),\n    albumentations.Rotate(p=0.5, limit=(-5, 5), interpolation=2, border_mode=2)\n])\n\ntrain_datagen = ImageDataAugmentor(\n    rescale=1./255,\n    validation_split=VAL_SPLIT,\n    seed=RANDOM_SEED,\n    augment=AUGMENTATIONS,\n    preprocess_input=None)\n\ntrain_generator = train_datagen.flow_from_directory(\n    PATH+'train/',     # the directory where the folders with pictures are located \n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True, \n    subset='training') # set as training data\n\ntest_generator = train_datagen.flow_from_directory(\n    PATH+'train/',\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True, \n    subset='validation') # set as validation data\n\n# change patience form 3 to 2 on reduceOnPlateou\ncallbacks_list = callbacks(lr=LR)","metadata":{"execution":{"iopub.status.busy":"2022-01-23T09:06:45.778966Z","iopub.execute_input":"2022-01-23T09:06:45.779246Z","iopub.status.idle":"2022-01-23T09:06:46.856342Z","shell.execute_reply.started":"2022-01-23T09:06:45.779215Z","shell.execute_reply":"2022-01-23T09:06:46.855616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training\nhistory = model.fit(\n        train_generator,\n        steps_per_epoch = train_generator.samples//train_generator.batch_size, \n        validation_data = test_generator,\n        validation_steps = test_generator.samples//test_generator.batch_size, \n        epochs = EPOCHS,\n        callbacks = callbacks_list\n)\n\nplot_history(history)","metadata":{"execution":{"iopub.status.busy":"2022-01-23T09:06:49.560972Z","iopub.execute_input":"2022-01-23T09:06:49.561534Z","iopub.status.idle":"2022-01-23T12:51:06.538694Z","shell.execute_reply.started":"2022-01-23T09:06:49.561493Z","shell.execute_reply":"2022-01-23T12:51:06.538012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save(PATH_BEST_MODEL + 'model_step5_3.hdf5')\n\n# to save best model weights in file with individual name\nmodel.load_weights(PATH_BEST_MODEL + 'best_model.hdf5')\nmodel.save_weights(PATH_BEST_MODEL + 'best_model_st_5_3.hdf5')\n\nscores = model.evaluate(test_generator, verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","metadata":{"execution":{"iopub.status.busy":"2022-01-23T12:51:06.54198Z","iopub.execute_input":"2022-01-23T12:51:06.542173Z","iopub.status.idle":"2022-01-23T12:52:30.142676Z","shell.execute_reply.started":"2022-01-23T12:51:06.542148Z","shell.execute_reply":"2022-01-23T12:52:30.14183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## TTA","metadata":{}},{"cell_type":"code","source":"def save_submit_tta(PATH_TO_MODEL=PATH_BEST_MODEL, \n                    WEIGHTS_NAME='best_model.hdf5',\n                    RANDOM_SEED=42,\n                    steps_for_tta=10):\n    \n    AUGMENTATIONS = albumentations.Compose([\n        albumentations.CLAHE(p=0.25, clip_limit=(1, 10), tile_grid_size=(10, 10)),\n        albumentations.ChannelShuffle(p=0.25),\n        albumentations.Equalize(p=0.25, mode='cv', by_channels=True),\n        albumentations.HorizontalFlip(p=0.5),\n        #albumentations.MotionBlur(p=0.25, blur_limit=(3, 7)),\n        #albumentations.RGBShift(p=0.5),\n        #albumentations.OneOf([\n        #    albumentations.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2),\n        #    albumentations.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1),\n        #],p=0.5),\n        albumentations.Rotate(p=0.5, limit=(-5, 5), interpolation=2, border_mode=2)\n    ])\n\n    test_sub_datagen = ImageDataAugmentor(\n        rescale=1./255,\n        validation_split=VAL_SPLIT,\n        seed=RANDOM_SEED,\n        augment=AUGMENTATIONS,\n        preprocess_input=None)\n\n    test_sub_generator = test_sub_datagen.flow_from_dataframe( \n        dataframe=sample_submission,\n        directory=PATH+'test_upload/',\n        x_col=\"Id\",\n        y_col=None,\n        shuffle=False,\n        class_mode=None,\n        target_size=(IMG_SIZE, IMG_SIZE),\n        batch_size=BATCH_SIZE)\n    \n    model = build_best_model(f_tune_coef=588, LR=LR,\n                             PATH=PATH_TO_MODEL,\n                             WEIGHTS_NAME=WEIGHTS_NAME,\n                             train_all_base_layers=True)\n    \n    tta_steps = steps_for_tta\n    predictions_list = []\n    \n    for i in range(tta_steps):\n        test_sub_generator.reset()\n        preds = model.predict(test_sub_generator, steps=len(test_sub_generator),  verbose=1) \n        predictions_list.append(preds)\n    pred = np.mean(predictions_list, axis=0)\n    \n    predictions = np.argmax(pred, axis=-1) #multiple categories\n    label_map = (train_generator.class_indices)\n    label_map = dict((v,k) for k,v in label_map.items()) #flip k,v\n    predictions = [label_map[k] for k in predictions]\n    \n    filenames_with_dir=test_sub_generator.filenames\n    submission = pd.DataFrame({'Id':filenames_with_dir, 'Category':predictions}, columns=['Id', 'Category'])\n    submission['Id'] = submission['Id'].replace('test_upload/','')\n    submission.to_csv('submission_st_5_4.csv', index=False)\n    print('Save submit')\n    return submission","metadata":{"execution":{"iopub.status.busy":"2022-01-26T07:10:34.396398Z","iopub.execute_input":"2022-01-26T07:10:34.396758Z","iopub.status.idle":"2022-01-26T07:10:34.415075Z","shell.execute_reply.started":"2022-01-26T07:10:34.396720Z","shell.execute_reply":"2022-01-26T07:10:34.414258Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"submit_DF = save_submit_tta(PATH_TO_MODEL='../input/weights-aft-st-5-3/',\n                            WEIGHTS_NAME='best_model_st_5_3.hdf5')","metadata":{"execution":{"iopub.status.busy":"2022-01-26T07:10:39.070186Z","iopub.execute_input":"2022-01-26T07:10:39.070470Z","iopub.status.idle":"2022-01-26T07:35:46.088290Z","shell.execute_reply.started":"2022-01-26T07:10:39.070435Z","shell.execute_reply":"2022-01-26T07:35:46.087383Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Clean PATH\n#import shutil\n#shutil.rmtree(PATH)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Что еще можно сделать для улучшения модели!**\n\n\n→ Попробовать другие архитектуры сетей, например, SOTA на ImageNet позднее B6, дающие бОльшую точность.\n\n→ Поэкспериментировать с архитектурой «головы».\n\n→ Попробовать больше эпох на 5 этапе обучения.\n\n→ Использовать разные техники управления Learning Rate, например Sheduler, но он требует большего времени и исключение ограничения на сессию.\n\n→ Использовать внешние датасеты для дообучения модели.\n\n→ Обернуть модель в сервис на Flask (чтобы на практике отследить особенности внедрения DL-моделей в продакшн).","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}