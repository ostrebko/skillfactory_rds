Проект "Прогнозирование стоимости автомобиля по характеристикам, описанию и фотографии".  
Задача создать модель, которая будет предсказывать стоимость автомобиля. В качестве исходных данных были табличные данные с характеристиками автомобилей, описанием продавцов авто и фотографии.  
Целью данной работы было познакомиться с возможностью построения модели с использованием разного типа данных (Multi-Input сеть).  

Для работы с моделью в первую очередь была оценена "наивная" (Модель 1) и baseline модели. Наивная модель предсказывает среднюю цену по модели автомобиля и году выпуска. Данные модели необходимы для оценки качества более сложных моделей.  

Далее был проведен анализ табличных категориальных и числовых признаков (EDA). Анализ проведен в отдельном расшаренном файле https://www.kaggle.com/ostrebko/prolect-8-batmobil-eda. Также ноутбук можно скачать в данном проекте (prolect-8-batmobil-eda.ipynb).  

Следующим шагом была проведена обработка и нормировка признаков, в чтом числе на основе EDA (см. выше). Результатом работы стало получение таблицы данных для подачи в ML и DL - модели. В приведенном ноутбуке имеется строка с неактивным кодом, чтобы показать, какие новые признаки были созданы, однако их добавление не улучшило качество модели catboost (см. далее по тексту). При работе также были написаны отдельные функции для преобразования данных, чтобы можно было в последствии заново сгенерировать признаки, если потребуется возвращение к версии без изменений.

Для оценки качества моделей использовала метрика MAPE (Mean absolute percentage error) или Средняя абсолютная ошибка в процентах (см. https://en.wikipedia.org/wiki/Mean_absolute_percentage_error). 

Модель 2: Следующим шагом было создание модели "классического"  ML с помощью CatBoost (на основе градиентного бустинга), ее тренировка, оценка результата. Лучший полученный результат на тренировочной выборке составил 12,15%, что лучше, чем результаты наивной модели и Baseline. Результат на валидационной выборке, по которой оценивался submit был несколько хуже и составил 13.09%. 

Модель 3 представляет собой простую нейронная сеть с Dense слоями. В отличие от Baseline был добавлен слой BatchNormalization, изменен параметр units выходов в слоях Dense и слоев Dropout. Добавление большего числа скрытых слоев качество модели не улучшило. Лучший полученный результат на тренировочной выборке составил 10,29%, что гораздо лучше, чем результаты наивной модели и Baseline. Результат на валидационной выборке, по которой оценивался submit был несколько, но все же был достаточно высоким и составил 10.93%.

Модель 4 представляет собой с две нейронные сети, выхода которых объединяются в единую нейронную сеть (добавляется одна "голова"). Каждая нейронная сеть (без "головы") предназначена обработки разных типов данных: табличные данные и текст. Для работы с табличными данными использована Model 3 (см. выше). Для работы с текстовыми данными была использована нейронная сеть с ячейками LSTM. Текст перед подачей в нейронную сеть "очищался" от знаков препинания, чисел, пробелов и повторяющихся больше 2-х раз букв, а затем каждое слово приводилось в нормальную форму с помощью библиотеки pymorphy2 (MorphAnalyzer), исключались "стоп-слова" (библиотека ntlk, stopwords). Дополнительно был добавлен фильтр с исключением часто и редко встречающихся слов. Далее обработанный текст токенизировался и векторизовался для последующей подачи в нейронную сеть. При работе нейронной сетью для обработки текста также в отличие от Baseline был добавлен слой BatchNormalization, изменен параметр units выходов в слоях Dense и слоев Dropout. Добавление большего числа скрытых слоев качество модели не улучшило. Лучший полученный результат на тренировочной выборке составил 10.19% (в отдельном случае был достигнут результат 10.12%, но повторить данный результат не получилось). Качество модели оказалось лучше, чем результаты наивной модели, Baseline и Модели 3, при этом лучший Результат на валидационной выборке, по которой оценивался submit, составил 10.85%, а добавление округления предсказания модели до 4 знака ДО запятой улучшило результат на 1 процент. Также использование более простой обработки текста (исключение стоп-слов и lemmatizer библиотеки ntlk) в совокупности вышеуказанным округлением позволили поднять результат на валидационной выборке до 10.80%. Что является лучшим результатом.

Дополнительно было проанализировано качество для Модели 5, которая строилась аналогично Модели 4 с добавлением нейронной сети EfficientNetB3 (Tranfer Learning) для анализа изображений (фото объявлений) с единой "головой" для трех подсетей. Для картинок в качестве предварительной обработки проводилась аугментация и были опробованы разные преобразования. Работа в данном направлении к улучшению качества модели не привело, при тренировке модели на текстовой выборке достигалось качество до 11,5%. Были опробованы разные аугментации и разные скорости уменьшения learning rate с помощью callback (ReduceLROnPlateau) при обучении модели. 

Аналогично было попробовано ансамблирование градиентного бустинга и нейронных сетей, но улучшения качества также не было достигнуто.
Проброс признака, который описан в baseline, на преобразованных данных приводил к ошибке. С учетом deadline было решено зафиксировать достигнутый результат.

Выводы по работе:
1. Была проведена большая работа по обработке данных, в т.ч. преобразовании текстовых для анализа модели. 
2. В процессе работы над моделью познакомился с созданием сети, состоящей из нейронных подсетей, которые на вход принимают разного рода данные (табличные данные, текст и изображения), обрабатывают и передают данные в слой, который объединяет данные и делает предсказание. Объединение нейронных сетей с различными типами данных может улучшить предсказание модели, однако это также сильно увеличивает возможное количество изменяемых параметров. Для работы с большим проектом уже нужна команда, которая будет работать над улучшением отдельного блока/части модели.
3. Большая часть преобразований по улучшению модели были опробованы, за исключением использование более сложной архитектуры обработки изображений и анализ результатов (где модель ошибается).
